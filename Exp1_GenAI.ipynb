{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSnVAp3ABWgLJ6ZnT1jT06",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amitabh-Phule/GenAi/blob/main/Exp1_GenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Objectives**\n",
        "\n",
        "1. Understand the concept of prompting in LLMs\n",
        "\n",
        "2. Implement zero-shot, one-shot, and few-shot prompting\n",
        "\n",
        "3. Analyze the effectiveness of prompt engineering techniques"
      ],
      "metadata": {
        "id": "D7NZwETl1KjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APlIzz6320x0",
        "outputId": "5f610f32-ebb8-4c1f-c619-2b0fb15fa358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initialize LLM Client**"
      ],
      "metadata": {
        "id": "u-9MQ8QC5jT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "FbUNq6xQ26fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=\"\")"
      ],
      "metadata": {
        "id": "pQztfUpD3D1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LLM Request Function**"
      ],
      "metadata": {
        "id": "IqCsmNNb5qKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_llm(prompt: str, temperature: float = 0.7) -> str:\n",
        "    \"\"\"\n",
        "    Sends a prompt to the GenAI LLM and returns the response.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): The user prompt or one-shot prompt.\n",
        "        temperature (float): Controls creativity of the model (default 0.7)\n",
        "\n",
        "    Returns:\n",
        "        str: Model's text response\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=temperature\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "8WlHXOFS5sr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Zero-Shot Prompting**"
      ],
      "metadata": {
        "id": "VSLufrGZ5xYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Zero-Shot Prompting ===\")\n",
        "zero_prompt = input(\"Enter your zero-shot prompt for the AI: \")\n",
        "zero_result = ask_llm(zero_prompt)\n",
        "print(\"\\nZero-Shot AI Response:\\n\", zero_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPPfjhIa5vqj",
        "outputId": "7663c8d6-2d66-4e96-9300-703d4ce01f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Zero-Shot Prompting ===\n",
            "Enter your zero-shot prompt for the AI: who is pm of india?\n",
            "\n",
            "Zero-Shot AI Response:\n",
            " As of my last knowledge update in October 2023, the Prime Minister of India is Narendra Modi. He has been in office since May 26, 2014. Please verify with a current source to ensure this information is still accurate.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **One-Shot Prompting**"
      ],
      "metadata": {
        "id": "usy5Y2OS567a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the example for one-shot\n",
        "example_input = \"Translate 'Hello' to Spanish.\"\n",
        "example_output = \"Hola\"\n",
        "\n",
        "# User input for one-shot task\n",
        "user_input = input(\"Enter your text to process (one-shot style): \")\n",
        "\n",
        "# Construct one-shot prompt\n",
        "one_shot_prompt = f\"\"\"Example:\n",
        "Input: {example_input}\n",
        "Output: {example_output}\n",
        "\n",
        "Now, process this:\n",
        "Input: {user_input}\n",
        "Output:\"\"\"\n",
        "\n",
        "# Call the existing function\n",
        "one_shot_result = ask_llm(one_shot_prompt)\n",
        "\n",
        "# Print the AI response\n",
        "print(\"\\nOne-Shot AI Response:\\n\", one_shot_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T51-2Xf05993",
        "outputId": "0291d688-5ec6-457f-d3ba-4ef06e4b21ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your text to process (one-shot style): give me example of addition of two numbers is 12\n",
            "\n",
            "One-Shot AI Response:\n",
            " The addition of two numbers that equals 12 could be: 5 + 7 = 12.\n"
          ]
        }
      ]
    }
  ]
}